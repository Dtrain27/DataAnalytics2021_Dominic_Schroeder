EPI_2010_data <- read.csv("data\\2010EPI_data.csv",skip = 1, header = T)
attach(EPI_2010_data)
View(EPI_2010_data)
EPI_2010_data <- na.omit(EPI_2010_data)
ggplot(EPI_2010_data, aes(x=EPI_2010_data$EPI)) + geom_histogram(binwidth = 1)
ggplot(EPI_2010_data, aes(x=EPI_2010_data$DALY)) + geom_histogram(binwidth = 1)
# Read the EPI csv data
EPI_data <- read.csv(file.choose())
################################################################################
#                                  Lab 2 Part 1A                               #
################################################################################
library(ggplot2)
if (FALSE) {
"
The function below is designed to find the central tendency information for the
column supplied.
Note: This function also does data cleaning as well
"
}
find_central_tendencies <- function(data) {
# Filter out the NA data
tf <- is.na(data) # records True values if the value is NA
data <- data[!tf]
# Print the Median, Mean, Max and Min values
print(summary(data))
# Find the mode of the EPI column
find_mode(data)
}
if(FALSE) {
"
The function below is used for identifying the mode of
the column or data supplied.
Taken from: https://stackoverflow.com/questions/2547402/how-to-find-the-statistical-mode
"
}
find_mode <- function(data) {
unique_vals <- unique(data)
mode <- unique_vals[which.max(tabulate(match(data, unique_vals)))]
print(paste("The column's Mode is: ",mode))
}
if (FALSE) {
"
Generate Central Tendency information for the EPI dataset
"
}
# Read the EPI csv data
EPI_data <- read.csv(file.choose())
attach(EPI_data)
EPI_Column <- as.numeric(EPI_data$EPI)
find_central_tendencies(data = EPI_Column)
DALY_Column <- as.numeric(EPI_data$DALY)
find_central_tendencies(data = DALY_Column)
if (FALSE) {
"
Generate Histograms for the EPI 2010 dataset EPI and DALY columns
"
}
# Read the EPI 2010 csv data
EPI_2010_data <- read.csv(file.choose(),skip = 1, header = T)
attach(EPI_2010_data)
EPI_2010_data <- na.omit(EPI_2010_data)
ggplot(EPI_2010_data, aes(x=EPI_2010_data$EPI)) + geom_histogram(binwidth = 1)
ggplot(EPI_2010_data, aes(x=EPI_2010_data$DALY)) + geom_histogram(binwidth = 1)
################################################################################
#                                  Lab 2 Part 1B                               #
################################################################################
install.packages("corrplot")
install.packages("corrplot")
library(corrplot)
library(dplyr)
if (FALSE) {
"
The function below is designed to find the most important factor in a given region
"
}
find_most_imptnt_fctr <- function(data, region) {
attach(data)
# Filter the data on the selected region
regional_data <- data %>% filter(data$EPI_regions == region)
# Remove string related fields
Data_To_Be_Correlated = regional_data[,-c(1:5)]
# Strip out all rows containing a NA
#Data_To_Be_Correlated <- Data_To_Be_Correlated[complete.cases(Data_To_Be_Correlated), ]
# Generate the correlation matrix
correlations.cor = cor(Data_To_Be_Correlated)
corr_df = data.frame(
row=rownames(correlations.cor)[row(correlations.cor)],
col=colnames(correlations.cor)[col(correlations.cor)],
corr=c(correlations.cor)
)
attach(corr_df)
# Sort the data in decreasing order
corr_df <- corr_df[order(corr_df$corr, decreasing = TRUE),]
# Grab the EPI correlations
EPI_corrs <- corr_df %>% filter(corr_df$row == "EPI")
attach(EPI_corrs)
# Grab the second item in the list since EPI will always have correlation of 1 to itself
print(paste("The most important factor in the region", region," is ",EPI_corrs$col[2]))
}
# Read the EPI csv data
EPI_data <- read.csv(file.choose())
attach(EPI_data)
find_most_imptnt_fctr(
data = EPI_data
,region = "South Asia"
)
if(FALSE) {
"
Run linear regression and Least squares in Environment Health using:
DALY
AIR_H
WATER_H
"
}
boxplot(ENVHEALTH,DALY,AIR_H,WATER_H)
lmENVH <- lm(ENVHEALTH~DALY+AIR_H+WATER_H)
lmENVH
summary(lmENVH)
cENVH<-coef(lmENVH)
if(FALSE) {
"
Run Prediction for user generated data
"
}
DALYNEW<-c(seq(5,95,5))
AIR_HNEW<-c(seq(5,95,5))
WATER_HNEW<-c(seq(5,95,5))
user_gend_data <- data.frame(DALYNEW,AIR_HNEW,WATER_HNEW)
pENV<-predict(lmENVH,user_gend_data,interval="prediction")
cENV<-predict(lmENVH,user_gend_data,interval="confidence")
DALY<-c(seq(5,95,5))
AIR_H<-c(seq(5,95,5))
WATER_H<-c(seq(5,95,5))
user_gend_data <- data.frame(DALY,AIR_H,WATER_H)
pENV<-predict(lmENVH,user_gend_data,interval="prediction")
cENV<-predict(lmENVH,user_gend_data,interval="confidence")
if(FALSE) {
"
Run linear regression and Least squares in Environment Health using:
AIR_E
CLIMATE
"
}
boxplot(ENVHEALTH,AIR_E,CLIMATE)
lmENVH <- lm(ENVHEALTH~AIR_E+CLIMATE)
lmENVH
summary(lmENVH)
cENVH<-coef(lmENVH)
if(FALSE) {
"
Run Prediction for user generated data
"
}
AIR_ENEW<-c(seq(5,95,5))
AIR_E<-c(seq(5,95,5))
CLIMATE<-c(seq(5,95,5))
user_gend_data <- data.frame(AIR_E,CLIMATE)
pENV<-predict(lmENVH,user_gend_data,interval="prediction")
cENV<-predict(lmENVH,user_gend_data,interval="confidence")
################################################################################
#                                  Lab 2 Part 2A                               #
################################################################################
regression_data <- read.csv(file.choose())
attach(regression_data)
# Columns we shall need
ROLL <- regression_data$ROLL
UNEM <- regression_data$UNEM
HGRAD <-  regression_data$HGRAD
INC <- regression_data$INC
# Build the linear regression model
model <- lm(ROLL ~ UNEM + HGRAD)
model
# Build a basic testing dataset for the model
test_data <- data.frame(
UNEM = c(7.0),
HGRAD = c(90000)
)
# Predict the value using our model
predict(model, newdata=test_data)
if(FALSE) {
"
Predict the ROLL again but include the INC column as a factor as well
"
}
# Build the linear regression model
model <- lm(ROLL ~ UNEM + HGRAD + INC)
model
# Build a basic testing dataset for the model
test_data <- data.frame(
UNEM = c(7.0),
HGRAD = c(90000),
INC = c(25000)
)
# Predict the value using our model
predict(model, newdata=test_data)
################################################################################
#                                  Lab 2 Part 2B                               #
################################################################################
# normalize the data using min max normalization
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
abalone <- read.csv(file.choose())
# Column names
colnames(abalone) <- c("sex", "length", 'diameter', 'height', 'whole_weight', 'shucked_wieght', 'viscera_wieght', 'shell_weight',
'rings' )
# summary on abalone
summary(abalone)
# Seperate the rings to be separated into three classes
abalone$rings <- as.numeric(abalone$rings)
abalone$rings <- cut(abalone$rings, br=c(-1,8,11,35), labels = c("young", 'adult', 'old'))
abalone$rings <- as.factor(abalone$rings)
summary(abalone$rings)
# remove the "sex" variable in abalone, because KNN requires all numeric variables for prediction
aba <- abalone
aba$sex <- NULL
aba[1:7] <- as.data.frame(lapply(aba[1:7], normalize))
summary(aba$shucked_wieght)
# After Normalization, each variable has a min of 0 and a max of 1.
# in other words, values are in the range from 0 to 1.
# We'll now split the data into training and testing sets.
ind <- sample(2, nrow(aba), replace=TRUE, prob=c(0.7, 0.3))
KNNtrain <- aba[ind==1,]
KNNtest <- aba[ind==2,]
k = round(sqrt(nrow(KNNtrain)))
library(class)
KNNpred <- knn(train = KNNtrain[1:7], test = KNNtest[1:7], cl = KNNtrain$rings, k = k)
KNNpred
table(KNNpred)
################################################################################
#                                  Lab 2 Part 2C                               #
################################################################################
# Load the iris data
data("iris")
iris
# Split the 5th column into a separate data frame
iris_species <- data.frame(Species = iris$Species)
# Remove the Species column from the data frame
iris$Species <- NULL
# kmeans clustering
k = 4
max_iterations = 1000
cluster <- kmeans(iris, k, iter.max = max_iterations, nstart = 1)
table(iris_species$Species,cluster$cluster)
print(getwd())
setwd("D:\\Data Analytics\\In Class Work\\")
print(getwd())
setwd("D:\\Data Analytics\\In Class Work\\")
setwd("D:\\Data Analytics\\DataAnalytics2021_Dominic_Schroeder\\In Class Work\\")
print(getwd())
# creating a matrix data with random numbers
# and plotting the matrix using the image() function
# you will see there, it does not have a real pattern in the plot.
set.seed(12345)
help(par)
# creating a matrix data with random numbers
# and plotting the matrix using the image() function
# you will see there, it does not have a real pattern in the plot.
set.seed(12345)
help(par)
# par can be used to set or query graphical parameters.
# Parameters can be set by specifying them as arguments
# to par in tag = value form, or by passing them as a list of tagged values.
par(mar = rep(0.2,4))
data_Matrix <-matrix(rnorm(400), nrow = 40)
image(1:10, 1:40, t(data_Matrix)[,nrow(data_Matrix):1])
help("heatmap")
help("rep")
par(mar=rep(0.2,4))
heatmap(data_Matrix)
help("rbinom")
set.seed(678910)
for (idx in 1:40) {
#flipping a coin and getting the data
coin_flip <- rbinom(1, size = 1, prob = 0.5)
# If the coin is Heads, add a common pattern to that row
if (coin_flip) {
data_Matrix[idx, ] <- data_Matrix[idx, ] + rep(c(0,3), each = 5)
}
}
par(mar= rep(0.2, 4))
image(1:10, 1:40, t(data_Matrix)[, nrow(data_Matrix):1])
par(mar=rep(0.2, 4))
heatmap(data_Matrix)
image(t(data_Matrix_Ordered)[, nrow(data_Matrix_Ordered):1])
hh <- hclust(dist(data_Matrix))
data_Matrix_Ordered <- data_Matrix[hh$ordered]
par(mfrow = c(1,3))
image(t(data_Matrix_Ordered)[, nrow(data_Matrix_Ordered):1])
image(t(data_Matrix_Ordered)[, nrow(data_Matrix_Ordered):1])
data_Matrix_Ordered <- data_Matrix[hh$ordered]
par(mfrow = c(1,3))
image(t(data_Matrix_Ordered)[, nrow(data_Matrix_Ordered):1])
data_Matrix_Ordered <- data_Matrix[hh$order,]
par(mfrow = c(1,3))
image(t(data_Matrix_Ordered)[, nrow(data_Matrix_Ordered):1])
plot(rowMeans(data_Matrix_Ordered), 40:1, ,xlab = "The Row Mean", ylab="Row", pch = 19)
plot(colMeans(data_Matrix_Ordered), xlab = "Column", ylab="Column Mean", pch = 19)
install(gdata)
Install(gdata)
#alternate
library("xlsx", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library("xlsx")
#alternate
bronx1<-read.xlsx(file.choose(),pattern="BOROUGH",stringsAsFactors=FALSE,sheetIndex=1,startRow=5,header=TRUE)
View(bronx1)
#
attach(bronx1) # If you choose to attach, leave out the "data=." in lm regression
SALE.PRICE<-sub("\\$","",SALE.PRICE)
SALE.PRICE<-as.numeric(gsub(",","", SALE.PRICE))
GROSS.SQUARE.FEET<-as.numeric(gsub(",","", GROSS.SQUARE.FEET))
LAND.SQUARE.FEET<-as.numeric(gsub(",","", LAND.SQUARE.FEET))
plot(log(GROSS.SQUARE.FEET), log(SALE.PRICE))
m1<-lm(log(SALE.PRICE)~log(GROSS.SQUARE.FEET))
m1<-lm(log(SALE.PRICE)~log(GROSS.SQUARE.FEET))
# Clean the data to remove NA rows
bronx1 <- na.omit(bronx1)
attach(bronx1) # If you choose to attach, leave out the "data=." in lm regression
# Select the data and split utilizing a REGEX
SALE.PRICE<-sub("\\$","",SALE.PRICE)
SALE.PRICE<-as.numeric(gsub(",","", SALE.PRICE))
GROSS.SQUARE.FEET<-as.numeric(gsub(",","", GROSS.SQUARE.FEET))
LAND.SQUARE.FEET<-as.numeric(gsub(",","", LAND.SQUARE.FEET))
plot(log(GROSS.SQUARE.FEET), log(SALE.PRICE))
m1<-lm(log(SALE.PRICE)~log(GROSS.SQUARE.FEET))
m1<-lm(SALE.PRICE~GROSS.SQUARE.FEET)
m1<-lm(0+log(SALE.PRICE)~0+log(GROSS.SQUARE.FEET))
log_sales_price <- log(SALE.PRICE)
# Compute the logs of the necessary data and clean the values
log_sales_price <- log(SALE.PRICE)
log_GSF <- log(GROSS.SQUARE.FEET)
logged_DF <- data.frame(
"LOG_SP" = log_sales_price,
"LOG_GSF" = log_GSF,
"LOG_LSF" = log_LSF
)
# Compute the logs of the necessary data and clean the values
log_sales_price <- log(SALE.PRICE)
log_GSF <- log(GROSS.SQUARE.FEET)
log_LSF <- log(LAND.SQUARE.FEET)
logged_DF <- data.frame(
"LOG_SP" = log_sales_price,
"LOG_GSF" = log_GSF,
"LOG_LSF" = log_LSF
)
logged_DF <- na.omit(logged_DF)
attach(logged_DF)
View(logged_DF)
View(logged_DF)
logged_DF <- na.omit(logged_DF)
attach(logged_DF)
View(logged_DF)
View(logged_DF)
logged_DF <- na.omit(logged_DF)
logged_DF <- logged_DF[!is.infinite(rowSums(logged_DF)),]
attach(logged_DF)
logged_DF <- logged_DF[!is.infinite(rowSums(logged_DF)),]
attach(logged_DF)
m1<-lm(log(SALE.PRICE)~log(GROSS.SQUARE.FEET))
m1<-lm(logged_DF$LOG_SP~logged_DF$LOG_GSF)
summary(m1)
abline(m1,col="red",lwd=2)
plot(resid(m1))
logged_DF <- data.frame(
"LOG_SP" = log_sales_price,
"LOG_GSF" = log_GSF,
"LOG_LSF" = log_LSF,
"FCTR_NEI" = fctr_NEIGHBOR,
"FCTR_BLDNG_CLSS" = fctr_BLDNG_CLSS
)
logged_DF <- na.omit(logged_DF)
fctr_NEIGHBOR <- factor(bronx1$NEIGHBORHOOD)
fctr_BLDNG_CLSS <- factor(bronx1$BUILDING.CLASS.CATEGORY)
logged_DF <- data.frame(
"LOG_SP" = log_sales_price,
"LOG_GSF" = log_GSF,
"LOG_LSF" = log_LSF,
"FCTR_NEI" = fctr_NEIGHBOR,
"FCTR_BLDNG_CLSS" = fctr_BLDNG_CLSS
)
logged_DF <- na.omit(logged_DF)
logged_DF <- logged_DF[!is.infinite(rowSums(logged_DF)),]
attach(logged_DF)
m1<-lm(logged_DF$LOG_SP~logged_DF$LOG_GSF)
logged_DF <- data.frame(
"LOG_SP" = log_sales_price,
"LOG_GSF" = log_GSF,
"LOG_LSF" = log_LSF,
"FCTR_NEI" = fctr_NEIGHBOR,
"FCTR_BLDNG_CLSS" = fctr_BLDNG_CLSS
)
logged_DF <- na.omit(logged_DF)
logged_DF <- logged_DF[!is.infinite(rowSums(logged_DF)),]
logged_DF <- data.frame(
"LOG_SP" = log_sales_price,
"LOG_GSF" = log_GSF,
"LOG_LSF" = log_LSF
)
logged_DF <- na.omit(logged_DF)
logged_DF <- logged_DF[!is.infinite(rowSums(logged_DF)),]
attach(logged_DF)
m1<-lm(logged_DF$LOG_SP~logged_DF$LOG_GSF)
summary(m1)
abline(m1,col="red",lwd=2)
plot(resid(m1))
abline(m1,col="red",lwd=2)
logged_DF <- data.frame(
"LOG_SP" = log_sales_price,
"LOG_GSF" = log_GSF,
"LOG_LSF" = log_LSF
)
logged_DF <- na.omit(logged_DF)
logged_DF <- logged_DF[!is.infinite(rowSums(logged_DF)),]
attach(logged_DF)
m1<-lm(logged_DF$LOG_SP~logged_DF$LOG_GSF)
summary(m1)
abline(m1,col="red",lwd=2)
plot(resid(m1))
# Model 2
m2<-lm(logged_DF$LOG_SP~logged_DF$LOG_GSF+logged_DF$LOG_LSF+factor(bronx1$NEIGHBORHOOD))
print(!is.infinite(rowSums(logged_DF)))
fctr_NEIGHBOR <- factor(bronx1$NEIGHBORHOOD[!is.infinite(rowSums(logged_DF)),])
fctr_NEIGHBOR <- factor(bronx1$NEIGHBORHOOD[!is.infinite(rowSums(logged_DF))])
# Model 2
m2<-lm(logged_DF$LOG_SP~logged_DF$LOG_GSF+logged_DF$LOG_LSF+factor(bronx1$NEIGHBORHOOD))
# Model 2
m2<-lm(logged_DF$LOG_SP~logged_DF$LOG_GSF+logged_DF$LOG_LSF+fctr_NEIGHBOR)
print(fctr_NEIGHBOR)
print(length(fctr_NEIGHBOR))
fctr_NEIGHBOR <- bronx1$NEIGHBORHOOD[!is.infinite(rowSums(logged_DF))]
fctr_NEIGHBOR <- factor(bronx1$NEIGHBORHOOD)[!is.infinite(rowSums(logged_DF))]
print(length(fctr_NEIGHBOR))
fctr_NEIGHBOR <- fctr_NEIGHBOR[!is.infinite(rowSums(logged_DF))]
print(length(fctr_NEIGHBOR))
print(!is.infinite(rowSums(logged_DF)))
fctr_NEIGHBOR <- fctr_NEIGHBOR[!is.infinite(rowSums(log_sales_price))]
fctr_NEIGHBOR <- fctr_NEIGHBOR[!is.infinite(rowSums(logged_DF))]
fctr_NEIGHBOR <- factor(bronx1$NEIGHBORHOOD)
fctr_NEIGHBOR <- fctr_NEIGHBOR[!is.infinite(rowSums(logged_DF))]
print(length(fctr_NEIGHBOR))
print(!is.infinite(rowSums(logged_DF)))
logged_DF <- data.frame(
"LOG_SP" = log_sales_price,
"LOG_GSF" = log_GSF,
"LOG_LSF" = log_LSF
)
logged_DF <- na.omit(logged_DF)
fctr_NEIGHBOR <- factor(bronx1$NEIGHBORHOOD)
fctr_BLDNG_CLSS <- factor(bronx1$BUILDING.CLASS.CATEGORY)
print(!is.infinite(rowSums(logged_DF)))
logged_DF <- logged_DF[!is.infinite(rowSums(logged_DF)),]
fctr_NEIGHBOR <- fctr_NEIGHBOR[!is.infinite(rowSums(logged_DF))]
fctr_BLDNG_CLSS <- factor(bronx1$BUILDING.CLASS.CATEGORY)
print(!is.infinite(rowSums(logged_DF)))
logged_DF <- data.frame(
"LOG_SP" = log_sales_price,
"LOG_GSF" = log_GSF,
"LOG_LSF" = log_LSF
)
logged_DF <- na.omit(logged_DF)
fctr_NEIGHBOR <- factor(bronx1$NEIGHBORHOOD)
fctr_NEIGHBOR <- fctr_NEIGHBOR[!is.infinite(rowSums(logged_DF))]
fctr_BLDNG_CLSS <- factor(bronx1$BUILDING.CLASS.CATEGORY)
print(!is.infinite(rowSums(logged_DF)))
logged_DF <- logged_DF[!is.infinite(rowSums(logged_DF)),]
attach(logged_DF)
m1<-lm(logged_DF$LOG_SP~logged_DF$LOG_GSF)
summary(m1)
abline(m1,col="red",lwd=2)
plot(resid(m1))
# Model 2
m2<-lm(logged_DF$LOG_SP~logged_DF$LOG_GSF+logged_DF$LOG_LSF+factor(bronx1$NEIGHBORHOOD))
# Model 2
m2<-lm(logged_DF$LOG_SP~logged_DF$LOG_GSF+logged_DF$LOG_LSF+fctr_NEIGHBOR)
summary(m2)
plot(resid(m2))
fctr_BLDNG_CLSS <- factor(bronx1$BUILDING.CLASS.CATEGORY)
fctr_BLDNG_CLSS <- fctr_BLDNG_CLSS[!is.infinite(rowSums(logged_DF))]
logged_DF <- data.frame(
"LOG_SP" = log_sales_price,
"LOG_GSF" = log_GSF,
"LOG_LSF" = log_LSF
)
logged_DF <- na.omit(logged_DF)
fctr_NEIGHBOR <- factor(bronx1$NEIGHBORHOOD)
fctr_NEIGHBOR <- fctr_NEIGHBOR[!is.infinite(rowSums(logged_DF))]
fctr_BLDNG_CLSS <- factor(bronx1$BUILDING.CLASS.CATEGORY)
fctr_BLDNG_CLSS <- fctr_BLDNG_CLSS[!is.infinite(rowSums(logged_DF))]
logged_DF <- logged_DF[!is.infinite(rowSums(logged_DF)),]
attach(logged_DF)
m1<-lm(logged_DF$LOG_SP~logged_DF$LOG_GSF)
summary(m1)
abline(m1,col="red",lwd=2)
plot(resid(m1))
# Model 2
m2<-lm(logged_DF$LOG_SP~logged_DF$LOG_GSF+logged_DF$LOG_LSF+fctr_NEIGHBOR)
summary(m2)
plot(resid(m2))
# Suppress intercept - using "0+ ..."
m2a<-lm(logged_DF$LOG_SP~0+logged_DF$LOG_GSF+logged_DF$LOG_LSF+fctr_NEIGHBOR)
summary(m2a)
plot(resid(m2a))
# Model 3
m3<-lm(logged_DF$LOG_SP~0+logged_DF$LOG_GSF+logged_DF$LOG_LSF+fctr_NEIGHBOR+factor(bronx1$BUILDING.CLASS.CATEGORY))
# Model 3
m3<-lm(logged_DF$LOG_SP~0+logged_DF$LOG_GSF+logged_DF$LOG_LSF+fctr_NEIGHBOR+fctr_BLDNG_CLSS)
summary(m3)
plot(resid(m3))
# Model 4
m4<-lm(logged_DF$LOG_SP~0+logged_DF$LOG_GSF+logged_DF$LOG_LSF+fctr_NEIGHBOR*fctr_BLDNG_CLSS)
summary(m4)
plot(resid(m4))
