}
runexample <- FALSE
if (runexample) {
data(NewHavenResidential)
gpairs(NewHavenResidential)
}
data("Titanic")
help(rpart)
help("rpart")
attach(titanic_data)
titanic_data <- data("Titanic")
attach(titanic_data)
titanic_data <- data("Titanic")
attach(titanic_data)
titanic_data <- data("Titanic")
attach(titanic_data)
force(Titanic)
force(Titanic)
data.frame(data("Titanic"))
data(Titanic)
force(Titanic)
# Practice on the Titanic Data
library(titanic)
# Practice on the Titanic Data
install.packages("titanic")
library(titanic)
data(Titanic)
data(titanic)
data(titanic_train)
force(Titanic)
force(titanic_train)
attach(titanic_train)
View(titanic_train)
fit <- rpart(titanic_train$Survived ~ .)
library(rpart)
fit <- rpart(titanic_train$Survived ~ .)
fit <- rpart(titanic_train$Survived ~ ., data=titanic_train)
plot(fit)
tree <- rpart(titanic_train$Survived ~ ., data=titanic_train)
plot(fit)
help(ctree)
tree <- ctree((titanic_train$Survived ~ ., data=titanic_train)
tree <- ctree(titanic_train$Survived ~ ., data=titanic_train)
tree <- ctree(as.factor(titanic_train$Survived) ~ ., data=titanic_train)
library(gdata)
library("xlsx")
brooklyn<-read.xlsx(file.choose(),pattern="BOROUGH",stringsAsFactors=FALSE,sheetIndex=1,startRow=5,header=TRUE)
View(brooklyn)
brooklyn<-read.xlsx(file.choose(),pattern="BOROUGH",stringsAsFactors=FALSE,sheetIndex=1,startRow=5,header=TRUE)
# Clean the data to remove NA rows
brooklyn <- na.omit(brooklyn)
############## PCA Analysis on the Boston Dataset ##############
install.packages('MASS')
data(Boston, package="MASS")
# Read the documentation of Boston dataset in RStudio to understand the dataset
help(Boston)
# Principal Component Analysis
# the prcomp() fucntion computes the principal components and we have turned on scalling
# Read the documentation for prcompt() function in RStudio
help(prcomp)
pca_out <- prcomp(Boston,scale. = T)
# pca_out shows the loadings that used.
pca_out
plot(pca_out)
# plotting using the biplot()
# Read the documentation for biplot() function in RStudio
help(biplot)
biplot(pca_out, scale = 0)
boston_pc <- pca_out$x
boston_pc
# boston_pc has the Principal Components having the same number of rows in the original dataset
head(boston_pc)
summary(boston_pc)
# plotting the boston_pc using the a line in plot() functions
plot(boston_pc, type = "l")
# Perform Linear regression on our data
regression_model<-lm(logged_DF$LOG_SP~0+logged_DF$LOG_GSF+logged_DF$LOG_LSF+fctr_NEIGHBOR+fctr_BLDNG_CLSS)
library(gdata)
library("xlsx")
library(corrplot)
library(dplyr)
library(mltools)
library(data.table)
brooklyn<-read.xlsx(file.choose(),pattern="BOROUGH",stringsAsFactors=FALSE,sheetIndex=1,startRow=5,header=TRUE)
# Add our factored data before randomly sampling the data
logged_DF$fctr_NEIGHBOR <- fctr_NEIGHBOR
# Select the data and split utilizing a REGEX
SALE.PRICE<-sub("\\$","",SALE.PRICE)
# Clean the data to remove NA rows
brooklyn <- na.omit(brooklyn)
attach(brooklyn)
# Select the data and split utilizing a REGEX
SALE.PRICE<-sub("\\$","",SALE.PRICE)
SALE.PRICE<-as.numeric(gsub(",","", SALE.PRICE))
GROSS.SQUARE.FEET<-as.numeric(gsub(",","", GROSS.SQUARE.FEET))
LAND.SQUARE.FEET<-as.numeric(gsub(",","", LAND.SQUARE.FEET))
plot(log(GROSS.SQUARE.FEET), log(SALE.PRICE))
# Compute the logs of the necessary data and clean the values
log_sales_price <- log(SALE.PRICE)
log_GSF <- log(GROSS.SQUARE.FEET)
log_LSF <- log(LAND.SQUARE.FEET)
logged_DF <- data.frame(
"LOG_SP" = log_sales_price,
"LOG_GSF" = log_GSF,
"LOG_LSF" = log_LSF
)
logged_DF <- na.omit(logged_DF)
fctr_NEIGHBOR <- factor(brooklyn$NEIGHBORHOOD)
fctr_NEIGHBOR <- fctr_NEIGHBOR[!is.infinite(rowSums(logged_DF))]
fctr_BLDNG_CLSS <- factor(brooklyn$BUILDING.CLASS.CATEGORY)
fctr_BLDNG_CLSS <- fctr_BLDNG_CLSS[!is.infinite(rowSums(logged_DF))]
# Perform One hot encoding
neighborhood <- one_hot(as.data.table(fctr_NEIGHBOR))
blding_class <- one_hot(as.data.table(fctr_BLDNG_CLSS))
logged_DF <- logged_DF[!is.infinite(rowSums(logged_DF)),]
attach(logged_DF)
##################### Plot the correlation matrix  #####################
logged_DF.cor <- cor(logged_DF)
# Add our factored data before randomly sampling the data
logged_DF$fctr_NEIGHBOR <- fctr_NEIGHBOR
logged_DF$fctr_BLDNG_CLSS <- fctr_BLDNG_CLSS
dt = sort(sample(nrow(logged_DF), nrow(logged_DF)*.7))
train<-logged_DF[dt,]
test<-logged_DF[-dt,]
# Perform Linear regression on our data
regression_model<-lm(logged_DF$LOG_SP~0+logged_DF$LOG_GSF+logged_DF$LOG_LSF+logged_DF$fctr_NEIGHBOR+logged_DF$fctr_BLDNG_CLSS)
summary(regression_model)
plot(resid(regression_model))
# Perform Linear regression on our data
regression_model<-lm(train$LOG_SP~0+train$LOG_GSF+train$LOG_LSF+train$fctr_NEIGHBOR+train$fctr_BLDNG_CLSS)
summary(regression_model)
plot(resid(regression_model))
# Run our predictions on the test data and compare the results
predict(regression_model, newdata = test)
View(test)
View(train)
# Perform Linear regression on our data
regression_model<-lm(train$LOG_SP~0+train$LOG_GSF+train$LOG_LSF+train$fctr_NEIGHBOR+train$fctr_BLDNG_CLSS, data=train)
summary(regression_model)
plot(resid(regression_model))
# Run our predictions on the test data and compare the results
predict(regression_model, newdata = test)
# Perform Linear regression on our data
regression_model<-lm(LOG_SP~0+LOG_GSF+LOG_LSF+fctr_NEIGHBOR+fctr_BLDNG_CLSS, data=train)
summary(regression_model)
plot(resid(regression_model))
# Run our predictions on the test data and compare the results
predict(regression_model, newdata = test)
library(ggplot2)
# Run our predictions on the test data and compare the results
predictions <- predict(regression_model, newdata = test)
plot(predictions, test$LOG_SP, xlab="predicted", ylab="actual")
abline(a=0,b=1)
# Perform Linear regression on our data
regression_model<-lm(LOG_SP~0+LOG_GSF+LOG_LSF+fctr_NEIGHBOR*fctr_BLDNG_CLSS, data=train)
summary(regression_model)
plot(resid(regression_model))
# Plot our predicted vs actual with a reference line to gauge our model
plot(predictions, test$LOG_SP, xlab="predicted", ylab="actual")
# Run our predictions on the test data and compare the results
predictions <- predict(regression_model, newdata = test)
abline(a=0,b=1)
corrplot(logged_DF.cor, method = "circle")
###############################################################################
#             Perform a significance test on the variables                    #
###############################################################################
fisher.test(contingencyMatrix, alternative = "greater")
###############################################################################
#             Perform a significance test on the variables                    #
###############################################################################
fisher.test(logged_DF, alternative = "greater")
View(logged_DF)
library(gdata)
library("xlsx")
library(corrplot)
library(dplyr)
library(mltools)
library(data.table)
library(ggplot2)
###############################################################################
#               Read and Clean the Data                                       #
###############################################################################
brooklyn<-read.xlsx(file.choose(),pattern="BOROUGH",stringsAsFactors=FALSE,sheetIndex=1,startRow=5,header=TRUE)
View(brooklyn)
# Clean the data to remove NA rows
brooklyn <- na.omit(brooklyn)
attach(brooklyn)
# Select the data and split utilizing a REGEX
SALE.PRICE<-sub("\\$","",SALE.PRICE)
SALE.PRICE<-as.numeric(gsub(",","", SALE.PRICE))
GROSS.SQUARE.FEET<-as.numeric(gsub(",","", GROSS.SQUARE.FEET))
LAND.SQUARE.FEET<-as.numeric(gsub(",","", LAND.SQUARE.FEET))
# Compute the logs of the necessary data and clean the values
log_sales_price <- log(SALE.PRICE)
log_GSF <- log(GROSS.SQUARE.FEET)
log_LSF <- log(LAND.SQUARE.FEET)
logged_DF <- data.frame(
"LOG_SP" = log_sales_price,
"LOG_GSF" = log_GSF,
"LOG_LSF" = log_LSF
)
logged_DF <- na.omit(logged_DF)
# Turn some of the miscellaneous but interesting columns into factors
fctr_NEIGHBOR <- factor(brooklyn$NEIGHBORHOOD)
fctr_NEIGHBOR <- fctr_NEIGHBOR[!is.infinite(rowSums(logged_DF))]
fctr_BLDNG_CLSS <- factor(brooklyn$BUILDING.CLASS.CATEGORY)
fctr_BLDNG_CLSS <- fctr_BLDNG_CLSS[!is.infinite(rowSums(logged_DF))]
logged_DF <- logged_DF[!is.infinite(rowSums(logged_DF)),]
attach(logged_DF)
###############################################################################
#               Plot a correlation matrix                                     #
###############################################################################
logged_DF.cor <- cor(logged_DF)
corrplot(logged_DF.cor, method = "circle")
###############################################################################
#             Perform a significance test on the variables                    #
###############################################################################
fisher.test(logged_DF, alternative = "greater")
###############################################################################
#             Perform a significance test on the variables                    #
###############################################################################
sp_v_gsf <- t.test(logged_DF$LOG_SP, logged_DF$LOG_GSF)
sp_v_lsf <- t.test(logged_DF$LOG_SP, logged_DF$LOG_LSF)
lsf_v_gsf <- t.test(logged_DF$LOG_GSF, logged_DF$LOG_LSF)
###############################################################################
#             Perform a significance test on the variables                    #
###############################################################################
sp_v_gsf <- t.test(logged_DF$LOG_SP, logged_DF$LOG_GSF,  paired = TRUE)
sp_v_lsf <- t.test(logged_DF$LOG_SP, logged_DF$LOG_LSF,  paired = TRUE)
lsf_v_gsf <- t.test(logged_DF$LOG_GSF, logged_DF$LOG_LSF,  paired = TRUE)
if sp
###############################################################################
#             Perform a significance test on the variables                    #
###############################################################################
T_TEST_THRESHOLD <- 0.05
sp_v_gsf <- t.test(logged_DF$LOG_SP, logged_DF$LOG_GSF,  paired = TRUE)
if (sp_v_gsf["p.value"] < T_TEST_THRESHOLD) {
print("The mean weight of log(Sales Prices) is different from the mean weight of log(Gross Square Feet)")
} else {
print("The mean weight of log(Sales Prices) is similar from the mean weight of log(Gross Square Feet)")
}
if (sp_v_lsf["p.value"] < T_TEST_THRESHOLD) {
print("The mean weight of log(Sales Prices) is different from the mean weight of log(Land Square Feet)")
} else {
print("The mean weight of log(Sales Prices) is similar from the mean weight of log(Land Square Feet)")
}
lsf_v_gsf <- t.test(logged_DF$LOG_GSF, logged_DF$LOG_LSF,  paired = TRUE)
if (lsf_v_gsf["p.value"] < T_TEST_THRESHOLD) {
print("The mean weight of log(Land Square Feet) is different from the mean weight of log(Gross Square Feet)")
} else {
print("The mean weight of log(Land Square Feet) is similar from the mean weight of log(Gross Square Feet)")
}
summary(regression_model)
# Perform Linear regression on our data
regression_model<-lm(LOG_SP~0+LOG_GSF+LOG_LSF+fctr_NEIGHBOR+fctr_BLDNG_CLSS, data=train)
# Compute the logs of the necessary data and clean the values
log_sales_price <- log(SALE.PRICE)
log_GSF <- log(GROSS.SQUARE.FEET)
log_LSF <- log(LAND.SQUARE.FEET)
logged_DF <- data.frame(
"LOG_SP" = log_sales_price,
"LOG_GSF" = log_GSF,
"LOG_LSF" = log_LSF
)
logged_DF <- na.omit(logged_DF)
# Turn some of the miscellaneous but interesting columns into factors
fctr_NEIGHBOR <- factor(brooklyn$NEIGHBORHOOD)
fctr_NEIGHBOR <- fctr_NEIGHBOR[!is.infinite(rowSums(logged_DF))]
fctr_BLDNG_CLSS <- factor(brooklyn$BUILDING.CLASS.CATEGORY)
fctr_BLDNG_CLSS <- fctr_BLDNG_CLSS[!is.infinite(rowSums(logged_DF))]
logged_DF <- logged_DF[!is.infinite(rowSums(logged_DF)),]
attach(logged_DF)
###############################################################################
#               Plot a correlation matrix                                     #
###############################################################################
logged_DF.cor <- cor(logged_DF)
corrplot(logged_DF.cor, method = "circle")
###############################################################################
#             Perform a significance test on the variables                    #
###############################################################################
T_TEST_THRESHOLD <- 0.05
sp_v_gsf <- t.test(logged_DF$LOG_SP, logged_DF$LOG_GSF,  paired = TRUE)
if (sp_v_gsf["p.value"] < T_TEST_THRESHOLD) {
print("The mean weight of log(Sales Prices) is different from the mean weight of log(Gross Square Feet)")
} else {
print("The mean weight of log(Sales Prices) is similar from the mean weight of log(Gross Square Feet)")
}
sp_v_lsf <- t.test(logged_DF$LOG_SP, logged_DF$LOG_LSF,  paired = TRUE)
if (sp_v_lsf["p.value"] < T_TEST_THRESHOLD) {
print("The mean weight of log(Sales Prices) is different from the mean weight of log(Land Square Feet)")
} else {
print("The mean weight of log(Sales Prices) is similar from the mean weight of log(Land Square Feet)")
}
lsf_v_gsf <- t.test(logged_DF$LOG_GSF, logged_DF$LOG_LSF,  paired = TRUE)
if (lsf_v_gsf["p.value"] < T_TEST_THRESHOLD) {
print("The mean weight of log(Land Square Feet) is different from the mean weight of log(Gross Square Feet)")
} else {
print("The mean weight of log(Land Square Feet) is similar from the mean weight of log(Gross Square Feet)")
}
# Add our factored data before randomly sampling the data
logged_DF$fctr_NEIGHBOR <- fctr_NEIGHBOR
logged_DF$fctr_BLDNG_CLSS <- fctr_BLDNG_CLSS
dt = sort(sample(nrow(logged_DF), nrow(logged_DF)*.7))
train<-logged_DF[dt,]
test<-logged_DF[-dt,]
# Perform Linear regression on our data
regression_model<-lm(LOG_SP~0+LOG_GSF+LOG_LSF+fctr_NEIGHBOR+fctr_BLDNG_CLSS, data=train)
summary(regression_model)
plot(resid(regression_model))
###############################################################################
#                   Test/Analyze the model                                    #
###############################################################################
# Run our predictions on the test data and compare the results
predictions <- predict(regression_model, newdata = test)
# Plot our predicted vs actual with a reference line to gauge our model
plot(predictions, test$LOG_SP, xlab="predicted", ylab="actual")
abline(a=0,b=1)
if (sp_v_gsf["p.value"] < T_TEST_THRESHOLD) {
print("The mean weight of log(Sales Prices) is different from the mean weight of log(Gross Square Feet)")
} else {
print("The mean weight of log(Sales Prices) is similar from the mean weight of log(Gross Square Feet)")
}
sp_v_lsf <- t.test(logged_DF$LOG_SP, logged_DF$LOG_LSF,  paired = TRUE)
if (sp_v_lsf["p.value"] < T_TEST_THRESHOLD) {
print("The mean weight of log(Sales Prices) is different from the mean weight of log(Land Square Feet)")
} else {
print("The mean weight of log(Sales Prices) is similar from the mean weight of log(Land Square Feet)")
}
lsf_v_gsf <- t.test(logged_DF$LOG_GSF, logged_DF$LOG_LSF,  paired = TRUE)
if (lsf_v_gsf["p.value"] < T_TEST_THRESHOLD) {
print("The mean weight of log(Land Square Feet) is different from the mean weight of log(Gross Square Feet)")
} else {
print("The mean weight of log(Land Square Feet) is similar from the mean weight of log(Gross Square Feet)")
}
help(hclust)
help(dist)
cluster <- hclust(dist(Titanic))
plot(cluster)
cluster <- hclust(dist(Titanic$Survived))
cluster <- hclust(dist(Titanic$Survived))
plot(cluster)
cluster <- hclust(dist(Titanic))
plot(cluster)
library(rpart)
library(titanic)
library(randomForest)
data(titanic_train)
attach(titanic_train)
tree <- rpart(titanic_train$Survived ~ ., data=titanic_train)
plot(fit)
tree <- rpart(titanic_train$Survived ~ ., data=titanic_train)
plot(fit)
plot(tree)
tree <- ctree(as.factor(titanic_train$Survived) ~ ., data=titanic_train)
tree <- rpart(titanic_train$Survived ~ ., data=titanic_train)
tree
help(ctree)
tree <- ctree(as.factor(titanic_train$Survived) ~ ., data=titanic_train)
plot(tree)
tree <- ctree(as.factor(titanic_train$Survived) ~ ., data=titanic_train)
cluster <- hclust(dist(Titanic))
plot(cluster)
model <- randomForest(factor(Survived) ~ ., data = Titanic, importance = TRUE)
model
model <- randomForest(Survived ~ ., data = Titanic, importance = TRUE)
model
model <- randomForest(Survived ~ ., data = Titanic, importance = TRUE)
model
model <- randomForest(Survived ~ ., data = Titanic, importance = TRUE)
model
# Practice on the Titanic Data
install.packages("party")
library(party)
tree <- ctree(as.factor(titanic_train$Survived) ~ ., data=titanic_train)
tree <- ctree(as.factor(Survived) ~ ., data=titanic_train)
tree <- rpart(titanic_train$Survived ~ ., data=titanic_train)
tree
tree <- ctree(as.factor(Survived) ~ ., data=titanic_train)
plot(tree)
tree <- ctree(as.factor(titanic_train$Survived) ~ ., data=titanic_train)
tree <- ctree(titanic_train$Survived ~ ., data=titanic_train)
tree <- ctree(titanic_train$Survived~PassengerId+Pclass+Age+SibSp+Parch+Fare, data=titanic_train)
plot(tree)
tree <- ctree(titanic_train$Survived~PassengerId+Survived+Pclass+Age+SibSp+Parch+Fare, data=titanic_train)
plot(tree)
cluster <- hclust(dist(titanic_train))
plot(cluster)
cluster <- hclust(dist(titanic_train$Survived))
plot(cluster)
model <- randomForest(Survived ~ ., data = titanic_train, importance = TRUE)
model
cluster <- hclust(dist(titanic_train$Survived))
plot(cluster)
cluster <- hclust(dist(titanic_train))
plot(cluster)
cluster <- hclust(dist(titanic_train$Survived~.))
cluster <- hclust(dist(titanic_train$Survived))
plot(cluster)
matrix <- dist(titanic_train$Survived)
matrix
cluster <- hclust(matrix)
plot(cluster)
matrix <- dist(titanic_train)
matrix
cluster <- hclust(matrix)
plot(cluster)
# There are 13 variables in the dataset such as Alcohol, Malic Acid, Ash, Alkalinity of Ash, Magnesium, ...
wine_data <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data", sep = ",")
head(wine_data)
# Peek at the data
head(wine_data)
nrow(wine_data)
# Noticed the colnames are missing and thus, we need to add them
# Adding the variable names
colnames(wine_data) <- c("Cvs", "Alcohol",
"Malic_Acid", "Ash", "Alkalinity_of_Ash",
"Magnesium", "Total_Phenols", "Flavanoids", "NonFlavanoid_Phenols",
"Proanthocyanins", "Color_Intensity", "Hue", "OD280/OD315_of_Diluted_Wine",
"Proline")
head(wine_data) # Now you can see the header names.
# Using the Heatmap() function, we can check the correlations,
# In the heatmap(), the "Dark Colors" represent the "Correlated"
# In the heatmap(), the "Light Colors" represent the "Not Correlated"
# Now we will use the heatmap() function to show the correlation among variables.
heatmap(cor(wine_data),Rowv = NA, Colv = NA)
# declaring the cultivar_classes using the factor() function each cultivar Cv1,Cv2 and Cv3.
cultivar_classes <- factor(wine_data$Cvs)
cultivar_classes
# We will not normalize the Cvs variable (first column) so we exclude the Cvs column with with -1
wine_data_PCA <- prcomp(scale(wine_data[,-1]))
# Get a summary of the PCA
summary(wine_data_PCA)
# Plot the PCA analysis
plot(wine_data_PCA)
# Plot a L line graph
plot(wine_data_PCA, type = "l")
# Create a biplot
biplot(wine_data_PCA)
# There are 13 variables in the dataset such as Alcohol, Malic Acid, Ash, Alkalinity of Ash, Magnesium, ...
wine_data <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data", sep = ",")
# Peek at the data
head(wine_data)
nrow(wine_data)
# Noticed the colnames are missing and thus, we need to add them
# Adding the variable names
colnames(wine_data) <- c("Cvs", "Alcohol",
"Malic_Acid", "Ash", "Alkalinity_of_Ash",
"Magnesium", "Total_Phenols", "Flavanoids", "NonFlavanoid_Phenols",
"Proanthocyanins", "Color_Intensity", "Hue", "OD280/OD315_of_Diluted_Wine",
"Proline")
head(wine_data) # Now you can see the header names.
# Using the Heatmap() function, we can check the correlations,
# In the heatmap(), the "Dark Colors" represent the "Correlated"
# In the heatmap(), the "Light Colors" represent the "Not Correlated"
# Now we will use the heatmap() function to show the correlation among variables.
heatmap(cor(wine_data),Rowv = NA, Colv = NA)
# declaring the cultivar_classes using the factor() function each cultivar Cv1,Cv2 and Cv3.
cultivar_classes <- factor(wine_data$Cvs)
cultivar_classes
# We will not normalize the Cvs variable (first column) so we exclude the Cvs column with with -1
wine_data_PCA <- prcomp(scale(wine_data[,-1]))
# Get a summary of the PCA
summary(wine_data_PCA)
# Plot the PCA analysis
plot(wine_data_PCA)
# Plot the PCA analysis
plot(wine_data_PCA)
# Plot a L line graph
plot(wine_data_PCA, type = "l")
# Create a biplot
biplot(wine_data_PCA)
library(rpart)
library(titanic)
library(randomForest)
library(party)
data(titanic_train)
attach(titanic_train)
part <- rpart(titanic_train$Survived ~ ., data=titanic_train)
part
plot(part)
part
tree <- ctree(titanic_train$Survived~PassengerId+Pclass+Age+SibSp+Parch+Fare, data=titanic_train)
plot(tree)
matrix <- dist(titanic_train$Survived)
matrix
cluster <- hclust(matrix)
plot(cluster)
model <- randomForest(Survived ~ ., data = titanic_train, importance = TRUE)
model <- randomForest(Survived ~ ., data = titanic_train, importance = TRUE)
model <- randomForest(titanic_train$Survived ~ ., data = titanic_train, importance = TRUE)
attach(titanic_train)
model <- randomForest(Survived ~ ., data = titanic_train, importance = TRUE)
model
titanic_train <- na.omit(titanic_train)
model <- randomForest(Survived ~ ., data = titanic_train, importance = TRUE)
model
data(titanic_train)
attach(titanic_train)
model <- randomForest(Survived ~ ., data = titanic_train)
titanic_train <- na.omit(titanic_train)
model <- randomForest(Survived ~ ., data = titanic_train)
model <- randomForest(as.factor(Survived) ~ ., data = titanic_train)
model
#titanic_train <- na.omit(titanic_train)
model <- randomForest(as.factor(Survived) ~ ., data = titanic_train)
model
data(titanic_train)
attach(titanic_train)
#titanic_train <- na.omit(titanic_train)
model <- randomForest(as.factor(Survived) ~ ., data = titanic_train)
model <- randomForest(as.factor(Survived) ~ ., data = titanic_train)
model
