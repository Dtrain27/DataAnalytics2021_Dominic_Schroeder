test_classes <- test_data[,13]
for (k in 1: 50) {
knn_model <- knn(training_data, test_data, cl=train_classes, k=k)
summary(knn_model)
predictions <- table(knn_model, test_classes)
confusionMatrix(predictions)
}
for (k in 1: 50) {
knn_model <- knn(training_data[,-13], test_data[,-13], cl=train_classes, k=k)
summary(knn_model)
predictions <- table(knn_model, test_classes)
confusionMatrix(predictions)
}
for (k in 1: 50) {
knn_model <- knn(training_data[,-13], test_data[,-13], cl=train_classes, k=k)
summary(knn_model)
predictions <- table(knn_model, test_classes)
confusionMatrix(predictions)
}
overall.accuracy <- confusionMatrix(predictions)$overall['Accuracy']
ideal_k <- 0
highest_accuracy <- 0
train_classes <- training_data[,13]
test_classes <- test_data[,13]
for (k in 1: 50) {
knn_model <- knn(training_data[,-13], test_data[,-13], cl=train_classes, k=k)
summary(knn_model)
predictions <- table(knn_model, test_classes)
overall.accuracy <- confusionMatrix(predictions)$overall['Accuracy']
# Keep track of our optimal k value
if (overall.accuracy > highest_accuracy) {
highest_accuracy = overall.accuracy
ideal_k = k
}
}
knn_model <- knn(training_data[,-13], test_data[,-13], cl=train_classes, k=ideal_k)
summary(knn_model)
predictions <- table(knn_model, test_classes)
confusionMatrix(predictions)
k
bank_data_url <- "http://archive.ics.uci.edu/ml/datasets/Bank+Marketing"
bank_data <- read.csv(bank_data_url, header = TRUE, sep = ";")
bank_data <- read.csv(bank_data_url)
bank_data <- read.csv(bank_data_url)
bank_data_url <- "http://archive.ics.uci.edu/ml/datasets/Bank+Marketing/bank-additional-full.csv"
bank_data <- read.csv(bank_data_url, header = TRUE, sep = ";")
bank_data <- read.csv(file.choose())
bank_data <- read.csv(file.choose(), header = TRUE, sep = ";")
################################################################################
# Do preliminary analysis on the data                                          #
################################################################################
summary(bank_data)
################################################################################
# Transform the data to ensure the character classes can be interpreted        #
################################################################################
bank_data$job <- as.factor(bank_data$job)
################################################################################
# Do preliminary analysis on the data                                          #
################################################################################
summary(bank_data)
################################################################################
# Transform the data to ensure the character classes can be interpreted        #
################################################################################
bank_data$job <- as.factor(bank_data$job)
bank_data$marital <- as.factor(bank_data$marital)
bank_data$education <- as.factor(bank_data$education)
bank_data$default <- as.factor(bank_data$default)
bank_data$housing <- as.factor(bank_data$housing)
bank_data$loan <- as.factor(bank_data$loan)
bank_data$contact <- as.factor(bank_data$contact)
bank_data$month <- as.factor(bank_data$month)
bank_data$day_of_week <- as.factor(bank_data$day_of_week)
bank_data$poutcome <- as.factor(bank_data$poutcome)
bank_data$y <- as.factor(bank_data$y)
################################################################################
# Do preliminary analysis on the data                                          #
################################################################################
summary(bank_data)
for ( col_idx in 1:ncols) {
boxplot(bank_data[[col_idx]])
mtext(names(bank_data)[col_idx], cex = 0.8, side = 1, line = 2)
}
par(box_plots)
View(wine)
# generate boxplots for each variable in the dataset
ncols <- as.numeric(ncol(bank_data))-1
box_plots <- par(mfrow = c(2,6))
for ( col_idx in 1:ncols) {
boxplot(bank_data[[col_idx]])
mtext(names(bank_data)[col_idx], cex = 0.8, side = 1, line = 2)
}
par(box_plots)
# generate boxplots for each variable in the dataset
ncols <- as.numeric(ncol(bank_data))-1
box_plots <- par(mfrow = c(2,6))
# generate boxplots for each variable in the dataset
ncols <- as.numeric(ncol(bank_data))-1
box_plots <- par(mfrow = c(2,6))
for ( col_idx in 1:ncols) {
ggplot(stack(bank_data), aes(x = names(bank_data)[col_idx], y = y)) + geom_boxplot()
}
# Assignment 7
# Level 6000
library(ggplot2)
for ( col_idx in 1:ncols) {
ggplot(stack(bank_data), aes(x = names(bank_data)[col_idx], y = y)) + geom_boxplot()
}
par(box_plots)
# generate boxplots for each variable in the dataset
ncols <- as.numeric(ncol(bank_data))-1
#Generate our correlation matrix
mydata.cor = cor(wine[1:ncols])
#Generate our correlation matrix
mydata.cor = cor(bank_data[1:ncols])
copy_of_data <- subset (df, select = -c(job,marital,education,default,housing,loan,contact,month,day_of_week,poutcome,y))
copy_of_data <- subset(df, select = -c(job,marital,education,default,housing,loan,contact,month,day_of_week,poutcome,y))
copy_of_data <- subset(bank_data, select = -c(job,marital,education,default,housing,loan,contact,month,day_of_week,poutcome,y))
copy_of_data <- subset(bank_data, select = -c(job,marital,education,default,housing,loan,contact,month,day_of_week,poutcome))
# generate boxplots for each variable in the dataset
ncols <- as.numeric(ncol(copy_of_data))-1
box_plots <- par(mfrow = c(2,6))
for ( col_idx in 1:ncols) {
boxplot(copy_of_data[[col_idx]])
mtext(names(copy_of_data)[col_idx], cex = 0.8, side = 1, line = 2)
}
par(box_plots)
# Generate histograms for each feature in our data
histgrams <- par(mfrow = c(6,3))
for ( col_idx in 1:ncols) {
truehist(copy_of_data[[col_idx]],  xlab = names(copy_of_data)[col_idx], col = 'lightgreen')
}
library(corrplot)
library(MASS)
library(e1071)
library(caTools)
library(caret)
library(class)
for ( col_idx in 1:ncols) {
truehist(copy_of_data[[col_idx]],  xlab = names(copy_of_data)[col_idx], col = 'lightgreen')
}
par(histgrams)
#Generate our correlation matrix
mydata.cor = cor(bank_data[1:ncols])
#Generate our correlation matrix
mydata.cor = cor(copy_of_data[1:ncols])
corrplot(mydata.cor)
#Generate our correlation matrix
mydata.cor = cor(copy_of_data[1:ncols])
corrplot(mydata.cor)
#Generate our correlation matrix
mydata.cor = cor(copy_of_data[1:ncols])
corrplot(mydata.cor)
#Generate our correlation matrix
mydata.cor = cor(copy_of_data[1:ncols+1])
corrplot(mydata.cor)
#Generate our correlation matrix
copy_of_data$y <- as.numeric(copy_of_data$y)
summary(copy_of_data)
copy_of_data$y
#Generate our correlation matrix
copy_of_data$y <- as.numeric(copy_of_data$y)
mydata.cor = cor(copy_of_data[1:ncols+1])
corrplot(mydata.cor)
# Assignment 7
# Level 6000
library(ggplot2)
library(corrplot)
library(MASS)
library(e1071)
library(caTools)
library(caret)
library(class)
bank_data <- read.csv(file.choose(), header = TRUE, sep = ";")
copy_of_data <- subset(bank_data, select = -c(job,marital,education,default,housing,loan,contact,month,day_of_week,poutcome))
# generate boxplots for each variable in the dataset
ncols <- as.numeric(ncol(copy_of_data))-1
box_plots <- par(mfrow = c(2,6))
for ( col_idx in 1:ncols) {
boxplot(copy_of_data[[col_idx]])
mtext(names(copy_of_data)[col_idx], cex = 0.8, side = 1, line = 2)
}
par(box_plots)
# Generate histograms for each feature in our data
histgrams <- par(mfrow = c(6,3))
for ( col_idx in 1:ncols) {
truehist(copy_of_data[[col_idx]],  xlab = names(copy_of_data)[col_idx], col = 'lightgreen')
}
par(histgrams)
#Generate our correlation matrix
copy_of_data$y <- as.numeric(copy_of_data$y)
mydata.cor = cor(copy_of_data[1:ncols+1])
corrplot(mydata.cor)
#Generate our correlation matrix
copy_of_data$y <- as.numeric(copy_of_data$y)
mydata.cor = cor(copy_of_data[1:ncols+1])
corrplot(mydata.cor)
copy_of_data <- subset(bank_data, select = -c(job,marital,education,default,housing,loan,contact,month,day_of_week,poutcome))
# generate boxplots for each variable in the dataset
ncols <- as.numeric(ncol(copy_of_data))-1
box_plots <- par(mfrow = c(2,6))
for ( col_idx in 1:ncols) {
boxplot(copy_of_data[[col_idx]])
mtext(names(copy_of_data)[col_idx], cex = 0.8, side = 1, line = 2)
}
par(box_plots)
# Generate histograms for each feature in our data
histgrams <- par(mfrow = c(6,3))
for ( col_idx in 1:ncols) {
truehist(copy_of_data[[col_idx]],  xlab = names(copy_of_data)[col_idx], col = 'lightgreen')
}
par(histgrams)
#Generate our correlation matrix
copy_of_data$y <- as.numeric(copy_of_data$y)
mydata.cor = cor(copy_of_data[1:ncols+1])
corrplot(mydata.cor)
#Generate our correlation matrix
copy_of_data$y <- as.numeric(as.factor(copy_of_data$y)
#Generate our correlation matrix
copy_of_data$y <- as.numeric(as.factor(copy_of_data$y)
#Generate our correlation matrix
copy_of_data$y <- as.numeric(as.factor(copy_of_data$y))
mydata.cor = cor(copy_of_data[1:ncols+1])
corrplot(mydata.cor)
#Generate our correlation matrix
copy_of_data$y <- as.factor(copy_of_data$y)
bank_data <- read.csv(file.choose(), header = TRUE, sep = ";")
copy_of_data <- subset(bank_data, select = -c(job,marital,education,default,housing,loan,contact,month,day_of_week,poutcome))
# generate boxplots for each variable in the dataset
ncols <- as.numeric(ncol(copy_of_data))-1
box_plots <- par(mfrow = c(2,6))
for ( col_idx in 1:ncols) {
boxplot(copy_of_data[[col_idx]])
mtext(names(copy_of_data)[col_idx], cex = 0.8, side = 1, line = 2)
}
par(box_plots)
# Generate histograms for each feature in our data
histgrams <- par(mfrow = c(6,3))
for ( col_idx in 1:ncols) {
truehist(copy_of_data[[col_idx]],  xlab = names(copy_of_data)[col_idx], col = 'lightgreen')
}
par(histgrams)
#Generate our correlation matrix
copy_of_data$y <- as.factor(copy_of_data$y)
copy_of_data$y <- as.numeric(copy_of_data$y)
mydata.cor = cor(copy_of_data[1:ncols+1])
corrplot(mydata.cor)
# Create some dummy variables so we can train against more than 1 category
dummies <- dummyVars(y ~ ., data = bank_data)
# Splitting data into train and test data
set.seed(42)
rows <- sample(nrow(wine))
rows <- sample(nrow(bank_data))
bank_data <- bank_data[rows, ]
split <- sample.split(bank_data, SplitRatio = 0.7)
training_data <- subset(bank_data, split == "TRUE")
test_data <- subset(bank_data, split == "FALSE")
library(randomForest)
rf_classifier <- randomForest(y ~ ., data = training_data, importance = TRUE, proximity = TRUE)
training_data <- subset(bank_data, split == "TRUE")
test_data <- subset(bank_data, split == "FALSE")
bank_data <- read.csv(file.choose(), header = TRUE, sep = ";")
copy_of_data <- subset(bank_data, select = -c(job,marital,education,default,housing,loan,contact,month,day_of_week,poutcome))
# generate boxplots for each variable in the dataset
ncols <- as.numeric(ncol(copy_of_data))-1
box_plots <- par(mfrow = c(2,6))
for ( col_idx in 1:ncols) {
boxplot(copy_of_data[[col_idx]])
mtext(names(copy_of_data)[col_idx], cex = 0.8, side = 1, line = 2)
}
par(box_plots)
# Generate histograms for each feature in our data
histgrams <- par(mfrow = c(6,3))
for ( col_idx in 1:ncols) {
truehist(copy_of_data[[col_idx]],  xlab = names(copy_of_data)[col_idx], col = 'lightgreen')
}
# Generate histograms for each feature in our data
histgrams <- par(mfrow = c(6,3))
for ( col_idx in 1:ncols) {
truehist(copy_of_data[[col_idx]],  xlab = names(copy_of_data)[col_idx], col = 'lightgreen')
}
# Assignment 7
# Level 6000
library(ggplot2)
library(corrplot)
library(MASS)
library(e1071)
library(caTools)
library(caret)
library(class)
for ( col_idx in 1:ncols) {
truehist(copy_of_data[[col_idx]],  xlab = names(copy_of_data)[col_idx], col = 'lightgreen')
}
par(histgrams)
#Generate our correlation matrix
copy_of_data$y <- as.factor(copy_of_data$y)
copy_of_data$y <- as.numeric(copy_of_data$y)
mydata.cor = cor(copy_of_data[1:ncols+1])
corrplot(mydata.cor)
#Generate our correlation matrix
copy_of_data$y <- as.factor(copy_of_data$y)
copy_of_data$y <- as.numeric(copy_of_data$y)
mydata.cor = cor(copy_of_data[1:ncols+1])
corrplot(mydata.cor)
# Create some dummy variables so we can train against more than 1 category
dummies <- dummyVars(y ~ ., data = bank_data)
# Splitting data into train and test data
set.seed(42)
rows <- sample(nrow(bank_data))
bank_data <- bank_data[rows, ]
split <- sample.split(bank_data, SplitRatio = 0.7)
training_data <- subset(bank_data, split == "TRUE")
test_data <- subset(bank_data, split == "FALSE")
rf_classifier <- randomForest(y ~ ., data = training_data, importance = TRUE, proximity = TRUE)
# redefine the variables to be factor based
bank_data$job <- as.factor(bank_data$job)
bank_data$marital <- as.factor(bank_data$marital)
bank_data$education <- as.factor(bank_data$education)
bank_data$default <- as.factor(bank_data$default)
bank_data$housing <- as.factor(bank_data$housing)
bank_data$loan <- as.factor(bank_data$loan)
bank_data$contact <- as.factor(bank_data$contact)
bank_data$month <- as.factor(bank_data$month)
bank_data$day_of_week <- as.factor(bank_data$day_of_week)
bank_data$poutcome <- as.factor(bank_data$poutcome)
bank_data$y <- as.factor(bank_data$y)
# Splitting data into train and test data
set.seed(42)
rows <- sample(nrow(bank_data))
bank_data <- bank_data[rows, ]
split <- sample.split(bank_data, SplitRatio = 0.7)
training_data <- subset(bank_data, split == "TRUE")
test_data <- subset(bank_data, split == "FALSE")
rf_classifier <- randomForest(y ~ ., data = training_data, importance = TRUE, proximity = TRUE)
# Limit the size of the bank data since I cannot allocate large data vectors
bank_data <- head(bank_data, 20000)
copy_of_data <- subset(bank_data, select = -c(job,marital,education,default,housing,loan,contact,month,day_of_week,poutcome))
# generate boxplots for each variable in the dataset
ncols <- as.numeric(ncol(copy_of_data))-1
box_plots <- par(mfrow = c(2,6))
for ( col_idx in 1:ncols) {
boxplot(copy_of_data[[col_idx]])
mtext(names(copy_of_data)[col_idx], cex = 0.8, side = 1, line = 2)
}
par(box_plots)
# Generate histograms for each feature in our data
histgrams <- par(mfrow = c(6,3))
for ( col_idx in 1:ncols) {
truehist(copy_of_data[[col_idx]],  xlab = names(copy_of_data)[col_idx], col = 'lightgreen')
}
par(histgrams)
#Generate our correlation matrix
copy_of_data$y <- as.factor(copy_of_data$y)
copy_of_data$y <- as.numeric(copy_of_data$y)
mydata.cor = cor(copy_of_data[1:ncols+1])
corrplot(mydata.cor)
# redefine the variables to be factor based
bank_data$job <- as.factor(bank_data$job)
bank_data$marital <- as.factor(bank_data$marital)
bank_data$education <- as.factor(bank_data$education)
bank_data$default <- as.factor(bank_data$default)
bank_data$housing <- as.factor(bank_data$housing)
bank_data$loan <- as.factor(bank_data$loan)
bank_data$contact <- as.factor(bank_data$contact)
bank_data$month <- as.factor(bank_data$month)
bank_data$day_of_week <- as.factor(bank_data$day_of_week)
bank_data$poutcome <- as.factor(bank_data$poutcome)
bank_data$y <- as.factor(bank_data$y)
# Splitting data into train and test data
set.seed(42)
rows <- sample(nrow(bank_data))
bank_data <- bank_data[rows, ]
split <- sample.split(bank_data, SplitRatio = 0.7)
training_data <- subset(bank_data, split == "TRUE")
test_data <- subset(bank_data, split == "FALSE")
rf_classifier <- randomForest(y ~ ., data = training_data, importance = TRUE, proximity = TRUE)
rf_classifier
plot(rf_classifier)
predictions <- predict(rf_classifier, newdata=test_data[1:ncols])
predictions <- predict(rf_classifier, newdata=test_data[1:ncols], type ='class')
predictions <- predict(rf_classifier, newdata=test_data[,-21], type ='class')
predictions <- table(predictions, test_data[21])
confusionMatrix(predictions)
predictions <- table(rf_classifier, test_data[,-21])
predictions <- table(rf_classifier, test_data$y)
predictions <- table(rf_classifier, test_data[,21])
confusionMatrix(table(predictions, test_data[,21]))
data(economics, package="ggplot2") # load data
economics$index <- 1:nrow(economics) # create index variable
economics <- economics[1:80, ] # retail 80rows for better graphical understanding
loessMod10 <- loess(uempmed ~ index, data=economics, span=0.10) # 10% smoothing span
loessMod25 <- loess(uempmed ~ index, data=economics, span=0.25) # 25% smoothing span
loessMod50 <- loess(uempmed ~ index, data=economics, span=0.50) # 50% smoothing span
# Predict Loess
smoothed10 <- predict(loessMod10)
smoothed25 <- predict(loessMod25)
smoothed50 <- predict(loessMod50)
# From above plot, you would notice that as the span increases, the smoothing of the curve also increases.
# Plot it
plot(economics$uempmed, x=economics$date, type="l", main="Loess Smoothing and Prediction",
xlab="Date", ylab="Unemployment (Median)")
lines(smoothed10, x=economics$date, col="red")
lines(smoothed25, x=economics$date, col="green")
lines(smoothed50, x=economics$date, col="blue")
# LOWESS example using the Cars dataset
data("cars")
str(cars) # we see 50 observation and 2 variables
# now we create a plot, speed Vs distance
plot(speed ~ dist, data = cars)
# now we create a plot, speed Vs distance
plot(speed ~ dist, data = cars)
# LOWESS example using the Cars dataset
data("cars")
str(cars) # we see 50 observation and 2 variables
# LOWESS example using the Cars dataset
data(cars, package="LOWESS")
install.packages("LOWESS")
# LOWESS example using the Cars dataset
data(cars, package="LOWESS")
# LOWESS example using the Cars dataset
data(cars, package="lowess")
install.packages("lowess")
# LOWESS example using the Cars dataset
data(cars, package="lowess")
str(cars) # we see 50 observation and 2 variables
"""
I could not find the appropriate data for the cars dataset. The one I was utilizing
does not have a speed column so I'm not sure what data is being used
"""
# data set consists of percentage returns for the S&P 500 stock index over 1, 250 days, from the
# beginning of 2001 until the end of 2005
names(Smarket)
library(ISLR)
data("Smarket")
head(Smarket)
# data set consists of percentage returns for the S&P 500 stock index over 1, 250 days, from the
# beginning of 2001 until the end of 2005
names(Smarket)
dim(Smarket)
summary(Smarket)
cor(Smarket)
cor(Smarket[,-9])
attach(Smarket)
plot(Volume)
help("glm")
glm.fit.model1 = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Smarket, family = binomial)
summary(glm.fit.model1)
glm.probs <- predict(glm.fit.model1, type="response")
glm.probs[1:10]
contrasts(Direction)
glm.pred <- rep("Down", 1250) # this command creates a vector of 1,250 "Down" elements
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction)
mean(glm.pred == Direction)
# Next, in order to implement this strategy, we will first create a vector corresponding
# to the observations from 2001 through 2004. We will then use this vector
# to create a held out data set of observations from 2005.
train <- (Year <2005)
Smarket.2005 = Smarket[!train,]
dim(Smarket.2005)
Direction.2005 <- Direction[!train]
glm.fit.model2 <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 +Volume, data=Smarket,
family = binomial, subset = train)
glm.prob2 = predict(glm.fit.model2, Smarket.2005, type="response")
# Finally, we compute the predictions for 2005 and compare them to the actual movements
# of the market over that time period.
glm.pred2 <- rep("Down", 252)
glm.pred2[glm.prob2 > 0.5] = "Up"
table(glm.pred2, Direction.2005)
mean(glm.pred2 != Direction.2005)
mean(glm.pred2 == Direction.2005)
# Model 3
glm.fit.model3 <- glm(Direction ~ Lag1 + Lag2, data = Smarket, family = binomial,
subset = train)
glm.probs3 <- predict(glm.fit.model3, Smarket.2005, type = "response")
glm.pred3 <- rep("Down", 252)
glm.pred3[glm.probs3 > 0.5] = "Up"
table(glm.pred3, Direction.2005)
mean(glm.pred3 == Direction.2005)
names(iris)
dim(iris) # check the dimensions of the iris data
head(iris)
# setting the seed value
set.seed(555)
Train <- sample(1:nrow(iris), nrow(iris)/2)
iris_Train <- iris[Train,] # Traning dataset
irist_Test <- iris[-Train,] # Testing dataset
fit1 <- lda(Species ~ Sepal.Length + Sepal.Width +
Petal.Length + Petal.Width, data = iris_Train)
predict1 <- predict(fit1, iris_Train)
predict1_class <- predict1$class
# generating the confusion matrix using the table() function
table1 <- table(predict1_class, iris_Train$Species)
table1
# Calculating the Accuracy of the prediction
sum(diag(table1))/sum(table1)
# Calculating the Accuracy of the prediction
sum(diag(table1))/sum(table1)
# generating the confusion matrix using the table() function
table1 <- table(predict1_class, iris_Train$Species)
table1
# Calculating the Accuracy of the prediction
sum(diag(table1))/sum(table1)
# Do a quick summary on the wine data
summary(wine)
# generate boxplots for each variable in the dataset
ncols <- as.numeric(ncol(wine))-1
box_plots <- par(mfrow = c(2,6))
for ( col_idx in 1:ncols) {
boxplot(wine[[col_idx]])
mtext(names(wine)[col_idx], cex = 0.8, side = 1, line = 2)
}
par(box_plots)
